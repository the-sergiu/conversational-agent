<!DOCTYPE html>
<html>
<head>
    <title>Real-time Speech Recognition and Text-to-Speech</title>
    <style>
        body {
            font-family: Arial, sans-serif;
        }

        h1 {
            color: #333;
        }

        #status {
            margin-top: 20px;
            font-weight: bold;
        }

        #startButton {
            padding: 10px;
            background-color: #007bff;
            color: #fff;
            border: none;
            cursor: pointer;
            border-radius: 50%;
            transition: background-color 0.3s ease;
        }

        #startButton.listening {
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.1);
            }
            100% {
                transform: scale(1);
            }
        }
    </style>
</head>
<body>
    <h1>Audio only Chat</h1>
    <button id="startButton">Start Continuous Recognition</button>
    <p id="status"></p>

    <script>
        const startButton = document.getElementById('startButton');
        const status = document.getElementById('status');
        let ws;
        let mediaRecorder;
        let audioChunks = [];
    
        function startRecording() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        mediaRecorder = new MediaRecorder(stream);
                        audioChunks = [];
                        mediaRecorder.ondataavailable = event => {
                            audioChunks.push(event.data);
                        };
                        mediaRecorder.onstop = () => {
                            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                            const formData = new FormData();
                            formData.append('file', audioBlob, 'audio.wav');
                            fetch('http://127.0.0.1:8000/upload-audio', {
                                method: 'POST',
                                body: formData
                            }).then(response => response.json())
                            .then(data => {
                                ws.send(data.transcript);
                            });
                            startButton.textContent = 'Start Continuous Recognition';
                            startButton.onclick = startRecording; // Rebind the function to start button
                        };
                        mediaRecorder.start();
                        startButton.textContent = 'Recording... Click to send';
                        startButton.onclick = () => mediaRecorder.stop();
                    })
                    .catch(error => {
                        console.error(error);
                        status.innerText = 'Error accessing your microphone.';
                    });
            } else {
                status.innerText = 'Your browser does not support audio recording.';
            }
        }
    
        // function speakText(text) {
        //     let speech = new SpeechSynthesisUtterance(text);
        //     window.speechSynthesis.speak(speech);
        // }
        // const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        async function playAudio(text) {
            const response = await fetch('http://127.0.0.1:8000/text-to-speech', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ text: text })
            });

            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const source = audioContext.createBufferSource();
            const audioChunks = [];
            const reader = response.body.getReader();

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                audioChunks.push(value);
            }

            const blob = new Blob(audioChunks, { type: 'audio/wav' });
            const arrayBuffer = await blob.arrayBuffer();
            const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.start();
        }

        // function playBlobAsAudio(blob) {
        //     // Create a Blob URL and play it using an Audio element
        //     const url = URL.createObjectURL(blob);
        //     const audio = new Audio(url);
        //     audio.play();
        // }
    
        startButton.onclick = () => {
            ws = new WebSocket('ws://127.0.0.1:8000/ws');
            ws.onopen = () => {
                startRecording();
            };
            // ws.onmessage = (event) => {
            //     speakText(event.data);
            // };
            ws.onmessage = (event) => {
                playAudio(event.data);
            };
            ws.onerror = (event) => {
                console.error('WebSocket error:', event);
            };
            ws.onclose = () => {
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                }
                status.innerText = 'WebSocket disconnected.';
            };
        };
    </script>
    
    
</body>
</html>